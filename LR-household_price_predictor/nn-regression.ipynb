{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline as P\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = train.select_dtypes('O').columns\n",
    "norm_cols = ['GrLivArea','1stFlrSF','LotArea']\n",
    "\n",
    "\n",
    "log = FunctionTransformer(np.log1p)\n",
    "oe = OrdinalEncoder()\n",
    "n_pipe = ColumnTransformer(transformers = [\n",
    "    (\"LogScale\", log, norm_cols) , # Numerical\n",
    "    (\"Encoder\", oe, obj_cols ), # Categorical \n",
    "\n",
    "],\n",
    "remainder='passthrough')\n",
    "\n",
    "df_train = pd.DataFrame(n_pipe.fit_transform(train), columns=train.columns)\n",
    "df_train.fillna(df_train.mean())\n",
    "\n",
    "X = df_train.drop(columns=['SalePrice'])\n",
    "X = np.asarray(X).astype('float')\n",
    "\n",
    "y = df_train['SalePrice']\n",
    "y = np.asarray(y).astype('float')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[208500],\n",
       "       [181500],\n",
       "       [223500],\n",
       "       ...,\n",
       "       [266500],\n",
       "       [142125],\n",
       "       [147500]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(train.select_dtypes(['float','int']).drop(columns='SalePrice'))\n",
    "y = np.asarray(train['SalePrice'])\n",
    "y=y.reshape(-1,1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scale_x = scaler_x.fit_transform(X)\n",
    "scale_y = scaler_y.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test = train_test_split(scale_x, scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_67 (Dense)            (None, 12)                456       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 569\n",
      "Trainable params: 569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 2ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 1ms/step - loss: nan - mse: nan - mae: nan - val_loss: nan - val_mse: nan - val_mae: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscikit_learn\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasRegressor\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], input_shape\u001b[39m=\u001b[39;49m(X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]), kernel_initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnormal\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matt/Documents/GitHub/kaggle-competitions/LR-household_price_predictor/nn-regression.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Compile model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn/lib/python3.10/site-packages/keras/dtensor/utils.py:95\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m layout:\n\u001b[1;32m     93\u001b[0m       layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[0;32m---> 95\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/nn/lib/python3.10/site-packages/keras/layers/core/dense.py:113\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m@utils\u001b[39m\u001b[39m.\u001b[39mallow_initializer_layout\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    102\u001b[0m              units,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m              bias_constraint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    112\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 113\u001b[0m   \u001b[39msuper\u001b[39;49m(Dense, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    114\u001b[0m       activity_regularizer\u001b[39m=\u001b[39;49mactivity_regularizer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(units) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(units, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m units\n\u001b[1;32m    117\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/nn/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nn/lib/python3.10/site-packages/keras/engine/base_layer.py:433\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m       batch_size \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     batch_input_shape \u001b[39m=\u001b[39m (batch_size,) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39;49m(kwargs[\u001b[39m'\u001b[39;49m\u001b[39minput_shape\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    434\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_input_shape \u001b[39m=\u001b[39m batch_input_shape\n\u001b[1;32m    436\u001b[0m \u001b[39m# Manage initial weight values if passed.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_shape=(X_train.shape[1]), kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(X_train.shape[0], kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca8f2d674b9046bb412b4a902db08d9f4bbc1d7a7bc6dd425896ed0611675c6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
